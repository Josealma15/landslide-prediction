# -*- coding: utf-8 -*-
"""proyectoDeslizamientos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GhbAJG7Afxx3R7uyAuOXeXYFkhMR1QvG

# Importar librerias y datasets de google drive
"""

# Datasets de drive
from google.colab import drive

# Librerías para manipulación de Data y Gráficas
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Preparación de datos y configuración de pipeline para Machine Learning con scikit-learn
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder

# Métricas para evaluación de modelos de clasificación
from sklearn.model_selection import validation_curve
from sklearn.model_selection import cross_val_score
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Modelos para clasificacion
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB

df1998 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS1998.xlsx", skiprows=1, header=0)
df1999 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS1999.xlsx", skiprows=1, header=0)
df2000 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2000.xlsx", skiprows=1, header=0)
df2001 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2001.xlsx", skiprows=1, header=0)
df2002 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2002.xlsx", skiprows=1, header=0)
df2003 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2003.xlsx", skiprows=1, header=0)
df2004 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2004.xlsx", skiprows=1, header=0)
df2005 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2005.xlsx", skiprows=1, header=0)
df2006 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2006.xlsx", skiprows=1, header=0)
df2007 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2007.xlsx", skiprows=1, header=0)
df2008 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2008.xlsx", skiprows=2, header=0)
df2009 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2009.xlsx", skiprows=1, header=0)
df2010 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2010.xlsx", skiprows=1, header=0)
df2011 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2011.xlsx", skiprows=1, header=0)
df2012 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2012.xlsx", skiprows=1, header=0)
df2013 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2013.xlsx", skiprows=1, header=0)
df2014 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2014.xlsx", skiprows=3, header=0)
df2015 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2015.xlsx", skiprows=3, header=0)
df2016 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2016.xlsx", skiprows=3, header=0)
df2017 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2017.xlsx", skiprows=3, header=0)
df2018 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2018.xlsx", skiprows=3, header=0)
df2019 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2019.xlsx", skiprows=3, header=0)
df2020 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2020.xlsx", skiprows=3, header=0)
df2021 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2021.xlsx", skiprows=3, header=0)
df2022 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2022.xlsx", skiprows=3, header=0)
df2023 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2023.xlsx", skiprows=4, header=0)
df2024 = pd.read_excel("/content/drive/MyDrive/DataProyecto/EMERGENCIAS2024.xlsx", skiprows=4, header=0)

"""# Renombramos las columnas de DEPARTAMENTO a DEPTO"""

# Renombrar columnas a DEPTO
df2012 = df2012.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2013 = df2013.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2014 = df2014.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2015 = df2015.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2016 = df2016.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2017 = df2017.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2018 = df2018.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2019 = df2019.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2020 = df2020.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2021 = df2021.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2022 = df2022.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2023 = df2023.rename(columns={"DEPARTAMENTO": "DEPTO"})
df2024 = df2024.rename(columns={"DEPARTAMENTO": "DEPTO"})

"""# Verificar que los datos que no tengan fecha se le agreguen el año correspondiente pero si no tienen DEPTO eliminar ese dato porque no nos sirve"""

# Si la fecha está nula → poner el año correspondiente
df1998["FECHA"] = df1998["FECHA"].fillna("1998")
df1999["FECHA"] = df1999["FECHA"].fillna("1999")
df2000["FECHA"] = df2000["FECHA"].fillna("2000")
df2001["FECHA"] = df2001["FECHA"].fillna("2001")
df2002["FECHA"] = df2002["FECHA"].fillna("2002")
df2003["FECHA"] = df2003["FECHA"].fillna("2003")
df2004["FECHA"] = df2004["FECHA"].fillna("2004")
df2005["FECHA"] = df2005["FECHA"].fillna("2005")
df2006["FECHA"] = df2006["FECHA"].fillna("2006")
df2007["FECHA"] = df2007["FECHA"].fillna("2007")
df2008["FECHA"] = df2008["FECHA"].fillna("2008")
df2009["FECHA"] = df2009["FECHA"].fillna("2009")
df2010["FECHA"] = df2010["FECHA"].fillna("2010")
df2011["FECHA"] = df2011["FECHA"].fillna("2011")
df2012["FECHA"] = df2012["FECHA"].fillna("2012")
df2013["FECHA"] = df2013["FECHA"].fillna("2013")
df2014["FECHA"] = df2014["FECHA"].fillna("2014")
df2015["FECHA"] = df2015["FECHA"].fillna("2015")
df2016["FECHA"] = df2016["FECHA"].fillna("2016")
df2017["FECHA"] = df2017["FECHA"].fillna("2017")
df2018["FECHA"] = df2018["FECHA"].fillna("2018")
df2019["FECHA"] = df2019["FECHA"].fillna("2019")
df2020["FECHA"] = df2020["FECHA"].fillna("2020")
df2021["FECHA"] = df2021["FECHA"].fillna("2021")
df2022["FECHA"] = df2022["FECHA"].fillna("2022")
df2023["FECHA"] = df2023["FECHA"].fillna("2023")
df2024["FECHA"] = df2024["FECHA"].fillna("2024")

# Si el departamento está nulo → eliminar esa fila
df1998 = df1998.dropna(subset=["DEPTO", "EVENTO"])
df1999 = df1999.dropna(subset=["DEPTO", "EVENTO"])
df2000 = df2000.dropna(subset=["DEPTO", "EVENTO"])
df2001 = df2001.dropna(subset=["DEPTO", "EVENTO"])
df2002 = df2002.dropna(subset=["DEPTO", "EVENTO"])
df2003 = df2003.dropna(subset=["DEPTO", "EVENTO"])
df2004 = df2004.dropna(subset=["DEPTO", "EVENTO"])
df2005 = df2005.dropna(subset=["DEPTO", "EVENTO"])
df2006 = df2006.dropna(subset=["DEPTO", "EVENTO"])
df2007 = df2007.dropna(subset=["DEPTO", "EVENTO"])
df2008 = df2008.dropna(subset=["DEPTO", "EVENTO"])
df2009 = df2009.dropna(subset=["DEPTO", "EVENTO"])
df2010 = df2010.dropna(subset=["DEPTO", "EVENTO"])
df2011 = df2011.dropna(subset=["DEPTO", "EVENTO"])
df2012 = df2012.dropna(subset=["DEPTO", "EVENTO"])
df2013 = df2013.dropna(subset=["DEPTO", "EVENTO"])
df2014 = df2014.dropna(subset=["DEPTO", "EVENTO"])
df2015 = df2015.dropna(subset=["DEPTO", "EVENTO"])
df2016 = df2016.dropna(subset=["DEPTO", "EVENTO"])
df2017 = df2017.dropna(subset=["DEPTO", "EVENTO"])
df2018 = df2018.dropna(subset=["DEPTO", "EVENTO"])
df2019 = df2019.dropna(subset=["DEPTO", "EVENTO"])
df2020 = df2020.dropna(subset=["DEPTO", "EVENTO"])
df2021 = df2021.dropna(subset=["DEPTO", "EVENTO"])
df2022 = df2022.dropna(subset=["DEPTO", "EVENTO"])
df2023 = df2023.dropna(subset=["DEPTO", "EVENTO"])
df2024 = df2024.dropna(subset=["DEPTO", "EVENTO"])

"""# Unir los datasets de todos los años en uno solo"""

# Une todos los DataFrames en uno solo
dfUnido = pd.concat([df1998, df1999, df2000, df2001, df2002, df2003, df2004, df2005, df2006, df2007, df2008, df2009,
                     df2010, df2011, df2012, df2013, df2014, df2015, df2016, df2017, df2018, df2019, df2020, df2021, df2022, df2023, df2024], ignore_index=True)

"""# Visualizar el dataframe unido"""

# Dataframe unido
dfUnido

"""# Eliminar las columnas que no nos sirven, en este caso solo queremos conservar FECHA, DEPTO, MUNICIPIO y EVENTO:"""

# Seleccionar solo las columnas que quieres conservar
dfUnido = dfUnido[["FECHA", "DEPTO", "MUNICIPIO", "EVENTO"]]

# Verificar el resultado
dfUnido.columns

"""# En la columna fecha solo dejaremos el año y visualizamos el resultado organizado por orden cronologico"""

# Intentar convertir la fecha, ignorando las inválidas
dfUnido["FECHA"] = pd.to_datetime(dfUnido["FECHA"], format="%d/%m/%Y %I:%M:%S %p", errors="coerce")

# Eliminar filas con fechas inválidas (NaT)
dfUnido = dfUnido.dropna(subset=["FECHA"])

# Extraer solo el año de las fechas válidas
dfUnido["FECHA"] = dfUnido["FECHA"].dt.year

# Restablecer el índice a cero
dfUnido.reset_index(drop=True, inplace=True)
dfUnido = dfUnido.sort_values("FECHA")
dfUnido

"""# Limpiamos la columna DEPTO (Se devuelve un filtro booleano que selecciona solo las filas cuyo DEPTO NO esté en la lista y si estan las elimina)"""

# Eliminar columnas innecesarias
dfUnido = dfUnido[~dfUnido["DEPTO"].isin(["IRAK- IRAN", "OCEANO_PACIFICO", "NACION", "NACIONAL", "PERÚ", "ón del "])]
dfUnido['DEPTO'].unique()

"""# Limpiamos el resto de DEPTO y EVENTO (corregimos errores ortograficos y datos duplicados)"""

# Reemplazar datos y limpiar errores
dfUnido.replace({"SAN ANDRES " : "SAN ANDRES",
                "SAN ANDRES ISLAS" : "SAN ANDRES",
                "BOGOTA, D.C." : "BOGOTA",
                "ANTIOQUIA " : "ANTIOQUIA",
                "QUINDIO " : "QUINDIO",
                "LA GUAJIRA" : "GUAJIRA",
                "ANTIOQUIA-BOLIVAR-SUCRE" : "ANTIOQUIA",
                "Guaviare" : "GUAVIARE",
                "META/CAQUETA" : "META",
                "RISARALDA/CALDAS" : "RISARALDA",
                "VALLE " : "VALLE",
                "VALLE DEL CAUCA" : "VALLE",
                "PUERTO LIBERTADOr" : "PUERTO LIBERTADOR",
                "INCENDIO ESTRUCTURAL " : "INC.ESTRUCTURAL",
                "MAREJADAS" : "MAREJADA",
                "ACCIDENTE DE TRANSITO " : "ACCIDENTE DE TRANSITO",
                "ACCIDENTE FLUVIAL " : "ACCIDENTE FLUVIAL",
                "VARIOS" : "OTROS",
                "AR" : "OTROS",
                "TEMPORAL" : "OTROS",
                "RESCATE EN MONTAÑA" : "OTROS",
                "ACCIDENTE EN MINA" : "ACCIDENTE MINERO",
                "DELIZAMIENTO" : "DESLIZAMIENTO",
                "DESLIZAMIENTO " : "DESLIZAMIENTO",
                "INC.FORESTAL" : "INCENDIO FORESTAL",
                "ERUPCION " : "ERUPCION",
                "VENDAVAL " : "VENDAVAL",
                "AVALANCHA " : "AVALANCHA",
                "EXPLOSION " : "EXPLOSION",
                "SEQUIA " : "SEQUIA",
                "CRECIENTE SUBITA " : "CRECIENTE SUBITA",
                "INUNDACION " : "INUNDACION",
                "INCENDIO " : "INCENDIO",
                "ACCIDENTE " : "ACCIDENTE",
                "COLAPSO " : "COLAPSO",
                " INCENDIO" : "INCENDIO",
                " " : "INCENDIO",
                "INCENDIO VEHICULAR" : "INCENDIO",
                "INCENDIO FORESTAL " : "INCENDIO FORESTAL",
                "INCENDIO FORESTAL" : "INCENDIO",
                "INCENDIO DE RESIDUO VEGETAL" : "INCENDIO",
                "INCENDIO DE COBERTURA VEGETAL" : "INCENDIO",
                "INCENDIO DE COBERTURA VEGETAL " : "INCENDIO",
                "INC.ESTRUCTURAL" : "INCENDIO",
                "INCENDIO - OTROS" : "INCENDIO",
                "INCENDIO fORESTAL" : "INCENDIO",
                "QUEMA " : "INCENDIO",
                "QUEMA" : "INCENDIO",
                "INCENDIO\xa0" : "INCENDIO",
                "ACCIDENTE AEREO" : "ACCIDENTE",
                "ACCIDENTE AÉREO" : "ACCIDENTE",
                "ACCIDENTE TERRESTRE" : "ACCIDENTE",
                "ACCIDENTE MARITIMO" : "ACCIDENTE",
                "ACCIDENTE DE TRÁNSITO" : "ACCIDENTE",
                "ACCIDENTE DE TRANSITO" : "ACCIDENTE",
                "ACCIDENTE FLUVIAL" : "ACCIDENTE",
                "ACCIDENTE MINERO" : "ACCIDENTE",
                "ACCIDENTE POR CAIDA" : "ACCIDENTE",
                "ACCIDENTE TECNOLOGICO" : "ACCIDENTE",
                "ACCIDENTE TRANSITO" : "ACCIDENTE",
                "ACCIDENTE TRANSPORTE AEREO" : "ACCIDENTE",
                "ACCIDENTE TRANSPORTE AÉREO" : "ACCIDENTE",
                "ACCIDENTE TRANSPORTE MARITIMO O FLUVIAL" : "ACCIDENTE",
                "ACCIDENTE TRANSPORTE MARÍTIMO O FLUVIAL" : "ACCIDENTE",
                "ACCIDENTE TRANSPORTE TERRESTRE" : "ACCIDENTE",
                "ERUPCION VOLCANICA" : "ERUPCION",
                "DERRAME DE HIDROCARBUROS" : "DERRAME",
                "DERRAME QUIMICO" : "DERRAME",
                "COLAPSO ESTRUCTURAL" : "COLAPSO",
                "MAR DELEVA" : "MAR DE LEVA",
                "REMOCION EN MASA" : "DESLIZAMIENTO",
                "EROSION-INCENDIO ESTRUCTURAL" : "EROSION",
                "EROSION COSTERA" : "EROSION",
                "INCENDIO ESTRUCTURAL" : "INCENDIO",
                "SEQUIA/INCENDIOS FORESTALES" : "SEQUIA",
                "VENDAVAL-INCENDIO ESTRUCTURAL" : "VENDAVAL",
                "GRANIZADA" : "FENOMENO ATMOSFERICO",
                "HELADA" : "FENOMENO ATMOSFERICO",
                "HURACAN" : "FENOMENO ATMOSFERICO",
                "SEQUIA" : "FENOMENO ATMOSFERICO",
                "TORMENTA ELECTRICA" : "FENOMENO ATMOSFERICO",
                "TORNADO" : "FENOMENO ATMOSFERICO",
                "VENDAVAL" : "FENOMENO ATMOSFERICO",
                "Vendaval" : "FENOMENO ATMOSFERICO",
                "MAREJADA" : "FENOMENO ATMOSFERICO",
                "MAR DE LEVA" : "FENOMENO ATMOSFERICO",
                "MAREA ALTA" : "FENOMENO ATMOSFERICO",
                "LLUVIAS" : "FENOMENO ATMOSFERICO",
                "ONDA TROPICAL" : "FENOMENO ATMOSFERICO",
                "CICLON TROPICAL: DEPRESION/TORMENTA/HURACAN" : "FENOMENO ATMOSFERICO",
                "CICLÓN, TROPICAL, DEPRESIÓN/TORMENTA/HURACÁN" : "FENOMENO ATMOSFERICO",
                "AVALANCHA" : "FENOMENO ATMOSFERICO",
                "EVENTO VOLCANICO" : "ERUPCION",
                "ACTIVACIÓN VOLCANICA" : "ERUPCION",
                "MOVIMIENTO EN MASA" : "DESLIZAMIENTO",
                "AVENIDA TORRENCIAL " : "AVENIDA TORRENCIAL",
                "CRECIENTE SUBITA" : "CRECIENTE",
                "CRECIENTE SÚBITA" : "CRECIENTE",
                "Creciente Subita" : "CRECIENTE",
                "CONTAMINACION AMBIENTAL" : "CONTAMINACION",
                "CONTAMINACIÓN'" : "CONTAMINACION",
                "CONTAMINACIÓN" : "CONTAMINACION",
                "AMENAZAS CONCATENADAS O COMPLEJAS" : "AMENAZAS",
                "EVENTO MAYOR" : "EVENTO MASIVO",
                "FALLA GEOLOGICA" : "FALLA",
                "FALLA ESTRUCTURAL" : "FALLA",
                "IMERSION" : "INMERSION",
                "INMERSIoN" : "INMERSION",
                "INTOXICACION MASIVA" : "INTOXICACION",
                "INUNDACIoN" : "INUNDACION",
                "INUNDACIÓN" : "INUNDACION",
                "INUNDACIÓN " : "INUNDACION",
                "MATPEL" : "DERRAME",
                "MOVIMIENTO EN MASA " : "MOVIMIENTO EN MASA",
                "Movimiento en Masa" : "MOVIMIENTO EN MASA",
                "REMOCIÓN EN MASA " : "MOVIMIENTO EN MASA",
                "REMOCIÓN EN MASA" : "MOVIMIENTO EN MASA",
                "AGLOMERACIÓN DE PÚBLICO" : "OTROS",
                "CAIDA DE ARBOL" : "OTROS",
                "CASO FORTUITO" : "OTROS",
                "CASO FORTUITO" : "OTROS",
                "CONATO" : "OTROS",
                "DESAPARECIDO" : "OTROS",
                "DIAPIRISMO" : "OTROS",
                "EMERGENCIA SOCIAL" : "OTROS",
                "EPIDEMIA" : "OTROS",
                "COVID-19" : "OTROS",
                "DAÑO " : "OTROS",
                "DESABASTECIMIENTO DE AGUA" : "OTROS",
                "ANTROPOGENICO NO INTENCIONAL" : "OTROS",
                "PLAGA" : "OTROS",
                }, inplace=True)

"""# Comprobamos que los datos hayan quedado limpios"""

sorted(dfUnido['EVENTO'].unique())

sorted(dfUnido['DEPTO'].unique())

"""# Miramos la cantidad de datos que hay con EVENTO DESLIZAMIENTO que es el que nos interesa"""

# Contar cuantos registros tienen el evento DESLIZAMIENTO
cantidadDeslizamientos = dfUnido[dfUnido["EVENTO"] == "DESLIZAMIENTO"].shape[0]
print(f"Cantidad de registros con evento DESLIZAMIENTO: {cantidadDeslizamientos}")

"""# Identificar los departamentos con más y menos deslizamientos por año y analizas los cambios"""

# Miramos el numero de veces ocurrido un evento
dfUnido.groupby(["EVENTO"]).size()

"""# Ver los departamentos con mayor y menor deslizamientos"""

# Filtrar solo los registros de deslizamientos
df_deslizamientos = dfUnido[dfUnido["EVENTO"] == "DESLIZAMIENTO"]

# Contar deslizamientos por departamento
deslizamientos_por_depto = df_deslizamientos.groupby("DEPTO").size().sort_values(ascending=False)

# Los 5 con más deslizamientos
print("Departamentos con más deslizamientos:")
print(deslizamientos_por_depto.head(5))

# Los 5 con menos deslizamientos
print("\nDepartamentos con menos deslizamientos:")
print(deslizamientos_por_depto.tail(5))

"""# Ver los años con mayor y menor deslizamientos"""

# Contar deslizamientos por año
deslizamientos_por_anio = df_deslizamientos.groupby("FECHA").size().sort_values(ascending=False)

# Los 5 con más deslizamientos
print("Años con más deslizamientos:\n")
print(deslizamientos_por_anio.head(5))

# Los 5 con menos deslizamientos
print("\nAños con menos deslizamientos:\n")
print(deslizamientos_por_anio.tail(5))

"""# Gráfica de los datos"""

deslizamientos_por_depto.head(10).plot(kind="bar", title="Top 10 Departamentos con más deslizamientos")
plt.xticks(rotation=45, ha='right', fontsize=12)
plt.show()

deslizamientos_por_anio.plot(kind="bar", title="Deslizamientos por año")
plt.show()

"""# Aplicar encoding a las caracteristicas categoricas de deslizamiento o no"""

dfUnido["DESLIZAMIENTO (BINARIO)"] = dfUnido["EVENTO"].apply(
    lambda x: 1 if x in ["DESLIZAMIENTO"] else 0)
dfUnido.head()

"""# Creamos matriz de correlacion"""

# Copiamos el DataFrame para no modificar el original
df_corr = dfUnido.copy()

# Codificar columnas categóricas (DEPTO, MUNICIPIO, EVENTO)
label_encoder = LabelEncoder()
for col in ["DEPTO", "MUNICIPIO", "EVENTO"]:
    df_corr[col] = label_encoder.fit_transform(df_corr[col])

# Crear la matriz de correlación
matriz_corr = df_corr.corr()

# Mostrar el resultado
plt.figure(figsize=(10,6))
sns.heatmap(matriz_corr, annot=True, cmap="YlGnBu", fmt=".2f")
plt.title("Matriz de Correlación con variables categóricas codificadas")
plt.show()

# Filtrar solo los registros que son deslizamientos
df_deslizamientos = dfUnido[dfUnido["DESLIZAMIENTO (BINARIO)"] == 1]

# Contar deslizamientos por departamento
conteo = df_deslizamientos["DEPTO"].value_counts()

# Graficar
plt.figure(figsize=(12,6))
sns.barplot(x=conteo.index, y=conteo.values, palette="Reds_r")

# Poner labels y demas
plt.xticks(rotation=70)
plt.xlabel("Departamento")
plt.ylabel("Cantidad de Deslizamientos")
plt.title("Cantidad de deslizamientos por departamento")
plt.show()

# Creamos los valores X y y
X = dfUnido[["DEPTO", "FECHA"]].copy()
y = dfUnido["DESLIZAMIENTO (BINARIO)"]

# Codificar DPTO (departamento)
le_depto = LabelEncoder()
X["DEPTO"] = le_depto.fit_transform(X["DEPTO"])

# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Modelo DesicionTreeClasifier"""

# Obtener probabilidades por departamento
modelo = DecisionTreeClassifier(max_depth=5, random_state=42)
modelo.fit(X_train, y_train)

df_resultados = X_test.copy()

# Probabilidad de deslizamiento (columna índice 1 = prob. de clase 1)
df_resultados["Prob_Deslizamiento"] = modelo.predict_proba(X_test)[:, 1]

# Convertir los códigos de DPTO a nombres originales
df_resultados["DEPTO"] = le_depto.inverse_transform(df_resultados["DEPTO"])

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_predict = model.predict(X_test)

# Metricas desempeño del modelo con DecisionTreeClassifier
accuracy = accuracy_score(y_test, y_predict)
print('The accuracy of Decision Tree is {:.4f}'.format(accuracy))

confus_matrix = confusion_matrix(y_test, y_predict)
plt.title('Confusion matrix')

sns.heatmap(confus_matrix, annot=True, cmap='Reds', fmt='d')  # Formato entero
plt.xlabel('Predicted class')
plt.ylabel('Exact class')

serie = pd.Series(accuracy, index=['DecisionTreeClassifier'])
accuracy_DTmodel = pd.DataFrame({'accuracy': serie})

"""# KNeighbors Application"""

model = KNeighborsClassifier() # Creamos variable para modelo
model.fit(X_train, y_train)  # Ajustamos los datos al modelo

y_predict = model.predict(X_test) # Predicciones de variable Y

# Metricas desempeño del modelo con clasificador KNN
accuracy = accuracy_score(y_test, y_predict)
print('The accuracy of KNeighbors is {:.4f}'.format(accuracy))

confus_matrix = confusion_matrix(y_test, y_predict)
plt.title('Confusion matrix')

sns.heatmap(confus_matrix, annot=True, cmap='Reds', fmt='d')  # Formato entero
plt.xlabel('Predicted class')
plt.ylabel('Exact class')

serie = pd.Series(accuracy, index=['KNeighborsClassifier'])
accuracy_KNmodel = pd.DataFrame({'accuracy': serie})

"""# Modelo LogisticRegression"""

# Aca creamos un modelo de regresion logistica
model = LogisticRegression(max_iter = 1000)

model.fit(X_train, y_train)

# Utilizar el modelo entrenado para predecir las etiquetas (Rain_encoded) para el conjunto de datos de prueba (X_test)
# Genera un array (y_predict) que contiene las predicciones deel modelo (0 a 1) basado en las caracteristicas presentes en X_test
y_predict = model.predict(X_test)

## Métricas de precisión, qué tan bien trabaja el modelo Logistic Regression
accuracy = accuracy_score(y_test, y_predict)
print('The accuracy of Logistic Regression is {:.4f}'.format(accuracy))

## Una matriz de confusión nos indica cuándo el modelo predijo de forma correcta los 1 verdadero y los 0 falso
confus_matrix = confusion_matrix(y_test, y_predict)
plt.title('Confusion matrix')

# Graficar mapa de calor con resultados de matriz de confusion, el parametro annot permite visualizar los numeros dentro de cada cuadro
sns.heatmap(confus_matrix, annot=True, cmap='Reds', fmt='d')  # Formato entero
plt.xlabel('Predicted class')
plt.ylabel('Exact class')

# Guardar precisión como serie y DataFrame
serie = pd.Series(accuracy, index=['LogisticRegression'])
accuracy_Logmodel = pd.DataFrame({'accuracy': serie})

"""# Comparación de los tres modelos de predicción para saber cual es más acertado"""

accuracy_models = pd.concat([accuracy_Logmodel, accuracy_KNmodel, accuracy_DTmodel])
accuracy_models